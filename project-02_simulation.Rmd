---
title: "Project 2: Simulation"
author: "Xiangyi Wen; Tanner Huck"
date: ""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(BSDA)
```

## Part 1: Simulate to answer statistical questions

Part 1 includes three different simulations. For each simulation, include the code to run your simulation, a plot of your results, and an explanation of your results and what this simulation taught you about this statistical problem or topic. Each simulation will be worth (7) points. They will be graded based on the following: 

* Writing a function to generate data once (1 point) 
* Commenting your code and following the style guidelines (1.5 points) 
* Plotting your results, with a well-labeled plot that follows our visualization style guidelines (1 point) 
* Generating correct results (1.5 points)
* Describing the results (1.5 points)
* Explaining what this simulation taught you (1 point)

### Simulation 1

The birthday problem is a probability brain teaser. 

It asks, in a room of $n$ people, what is the probability that at least one pair of $2$ people share the same birthday. 

Let's simulate to find out! Assume birthdays are randomly drawn from the $365$ days of a non-leap year and each day is equally probable to be someone's birthday. Assume that the birthdays of everyone in the room are independent of each other. Simulate to estimate the probability of two people sharing a birthday in a set of $n$ people for values of $n$ in $\{5, 10, 15, 20, 25, 30, 35, 40, 45, 50\}$. 

For each size of room $n$ generate data $1000$ times. *Hint: use the function sample, and pay attention to the `replace` parameter.*

For this first problem I've written out psuedocode to answer this question through comments. For the next problems I suggest that you write out your own psuedocode as comments! 

```{r, eval = FALSE}
# set a variable for the number of replications
num_replication <- 1000
# create a vector for room sizes n 
n <- c(5,10,15,20,25,30,35,40,45,50)
# write a function to generate birthday data and check whether there is a shared birthday in the group. This function should take as input the value of n and return TRUE if two people share a birthday and FALSE otherwise (hint: the function sample will be helpful here!)
test_birthday <- function(n) {
  test <- vector(length = n)
  for (i in 1:n) {
    test[i] <- sample.int(365, 1)
  }
  return(!length(test) == length(unique(test)))
  #return(any(duplicated(test)))
}
# make a matrix to hold data from your replications 
replication <- matrix(nrow = num_replication, ncol = 10)
# run simulation 
for (sizeIndex in 1:length(n)) {
  for (testNum in 1:num_replication) {
    replication[testNum, sizeIndex] <- test_birthday(n[sizeIndex])
  }
}
# make result vector that gives the proportion of shared birthdays for each value of n 
result <- vector(length = length(n))
for (i in 1:length(n)) {
  result[i] <- mean(replication[,i])
}

# make dataframe for plotting that has a variable for sample size n and a variable for 
# proportion of shared birthdays for that value of n 
dataFrameResult <- data.frame(n,result)

# plot your results (as a well-labeled ggplot) to look at the relationship between n and 
# the probability of having a shared birthday 
ggplot(dataFrameResult, aes(n, result)) +
  geom_point() +
  geom_line() +
  labs(title = "Relationship between room size and the probability of having a shared birthday",
       x = "room size", y = "probability of having a shared birthday")
```

### Simulation 2

What is the relationship between sample size and the probability of a type I error? Recall that type I error is the probability of rejecting the null hypothesis given that it is true, so $\text{Probability of type I error} = P(\text{reject }H_0|H_0\text{ true})$

Look at the relationship between sample size and type I error for a two-sided t-test with null hypothesis that the population mean is equal to $1$, with an alpha level of $0.05$. This will look like `t.test(data, alternative = "two.sided", mu = 1)`. 

Do this in two cases, once when data comes from a normal distribution and once when data comes from an exponential distribution. Test sample sizes in the set $\{10, 20, 30, 40, 50, 60, 70, 80, 90, 100\}$. Generate data under the null hypothesis, where the normal data come from a normal distribution with mean $1$ and variance $1$ and the exponential data come from an exponential distribution with mean $1$ and variance $1$ (this corresponds with the argument `rate = 1` in the function `rexp`). 

For each sample size, simulate data $5000$ times. 

In your description of your results, be sure to define type I error. 

```{r}
n <- c(10,20,30,40,50,60,70,80,90,100)
num_replication <- 5000
replication_normal<- matrix(NA,nrow = num_replication,ncol = length(n))
replication_expon<- matrix(NA,nrow = num_replication,ncol = length(n))
test_error <- function(n) {
  data_normal <- rnorm(n, mean = 1)
  data_expon <- rexp(n, rate = 1)
  result <- matrix(NA,1,2)
  result[1] <- t.test(data_normal, alternative = "two.sided", mu = 1)$p.value < 0.05
  result[2] <- t.test(data_expon, alternative = "two.sided", mu = 1)$p.value < 0.05
  return(result)
}

for (sizeIndex in 1:length(n)) {
  for (testNum in 1:num_replication) {
    value <- test_error(n[sizeIndex])
    replication_normal[testNum, sizeIndex] <- value[1]
    replication_expon[testNum, sizeIndex] <- value[2]
  }
}

result <- matrix(NA, nrow = 2, ncol = length(n))
for (i in 1:length(n)) {
  result[1,i] <- mean(replication_normal[,i])
  result[2,i] <- mean(replication_expon[,i])
}

dataFrameResult <- data.frame(rep(n, 2), c(result[1,], result[2,]), c(rep("normal_distribution", 10), rep("exponential_distribution", 10)))
colnames(dataFrameResult) <- c("sample_size", "probability","distribution_type")

ggplot(dataFrameResult, aes(sample_size, probability, group = distribution_type, color = distribution_type)) +
  geom_point() +
  geom_line() +
  labs(title = "relationship between sample size and the probability of a type I error",
       x = "sample size", y = "probability of having a type I error")
```

### Simulation 3

Look at the relationship between the effect size (the magnitude of $\beta$) and the power of a t-test for a coefficient in a linear model. 

Recall that power is the probability of rejecting the null hypothesis given that it is false, so $\text{Power} = P(\text{reject }H_0|H_0\text{ false})$. Consider effect sizes for $\beta$ in the set $\{0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0\}$. Generate each response $Y_i$ from the following linear model:

$$Y_i = 5 + X_i\beta + \epsilon_i$$
$$\epsilon_i\sim N(0,1)$$
Use a sample size of $n = 100$. Use the $X$ vector below. 

```{r}
set.seed(302)
X <- rbinom(100, size = 1, prob = 0.5)
```

For each effect size (value of $\beta$), simulate data $1000$ times. In your description of your results, be sure to define power. 

## Part 2: Simulate to Teach 

### Simulation 4 

Simulation is often used as a tool to teach statistics. There are many theoretical results that are easier to explain to students through a simulation. Choose a statistical concept, theoretical result, or problem from a homework or exam from a previous statistics class. Design a simulation that would teach this topic or answer this question.

Some example topics include: simple random samples vs convenience samples, the probability of a certain event, the sampling distribution of the sample mean, confidence intervals, the central limit theorem, the difference between median and mode for data from a symmetric distribution vs a skewed distribution, etc. However, feel free to choose your own statistical topic! Please run your chosen topic by me in an email and get it approved before you start this part.

You should write this section as if you are teaching another student. Start with identifying the statistical topic and giving a brief overview. Then, run your simulation. Show your results in a table or plot. Explain your results to the student. Conclude with what you want them to take away from this simulation. 

Part 2 will be worth 9 points. The points will be assigned in the following way. 

* Introducing your topic and giving a brief overview (2.5 points)
* Commenting your code and following the style guidelines (1.5 points) 
* Plotting your results, with a well-labeled plot that follows our visualization style guidelines (1 point) 
* Describing the results (1.5 points)
* Explaining to the student the connection between your statistical problem and your simulation, and using your simulation to guide learning. (2.5 points)
